# -*- coding: utf-8 -*-
"""
hk_evolution_full.py
ÊúÄÁµÇÂÑ™ÂåñÁâàÔºöÂ§ßË¶èÊ®°Êï¥‰ΩµÂ§öÊ†ºÂºèÂêçÂñÆÔºå‰æÜÊ∫êÂèØËøΩÊ∫ØÔºàÊ™îÂêç/Â∑•‰ΩúË°®/ÂúãÂÆ∂ÔºâÔºå
ÂÆâÂÖ®Â≠ó‰∏≤Âåñ„ÄÅË®òÊÜ∂È´îÂèãÂñÑÔºå‰∏¶Ëº∏Âá∫Ê∏ÖÊô∞ÂΩôÁ∏ΩËàáÂàÜÈ°û„ÄÇ

‰æùË≥¥Ôºö
  pip install -U pandas openpyxl xlrd
  pip install pyexcel-xls pyexcel-io
  ÔºàÂèØÈÅ∏Ôºâpip install colorama tqdm

Âü∑Ë°åÔºö
  python hk_evolution_full.py [Ë≥áÊñôÂ§æË∑ØÂæë]

Ëº∏Âá∫Ôºö
  ./output/integrated_master.csv
  ./output/hk_in_au.csv / ./output/uncertain.csv / ./output/not_hk.csv
  ./output/email_domain_stats.csv / ./output/surname_stats.csv
  ./output/label_counts.csv / ./output/country_label_pivot.csv
  ÂãïÊÖãÁâπÂæµÂ∫´Ôºödynamic_*.txt ÊúÉÂú®Â∑•‰ΩúÁõÆÈåÑÁ∂≠Ë≠∑/Â¢ûË£ú

ÂÇôË®ªÔºö
- ‰ª•‰∏≤ÊµÅÂØ´Ê™îÈÅøÂÖç‰∏ÄÊ¨°ÊÄß‰ΩµÂ∑®Â§ß DataFrame ÁöÑË®òÊÜ∂È´îÁÇ∏Ë£Ç
- .xls ÂÑ™ÂÖàÂòóË©¶ pandas+xlrdÔºå‰∏çË°åËá™ÂãïÊîπÁî® pyexcel-xls
- Ê¨ÑÂêçÂÖàËΩâÂ≠ó‰∏≤‚ÜíÊ≠£Ë¶èÂåñÂ∞çÈΩäÂà∞ name/email/phone/addressÔºåÂÜçÂÅöË©ïÂàÜ
"""

import os, re, sys, glob, math, warnings
from pathlib import Path
from collections import Counter, defaultdict

import pandas as pd

# ÂèØÈÅ∏Â•ó‰ª∂
try:
    from tqdm import tqdm
except Exception:
    tqdm = None

try:
    from colorama import init as colorama_init, Fore, Style
    colorama_init(autoreset=True)
except Exception:
    class _Dummy: 
        RESET_ALL = ""
    class _C:
        RED = GREEN = YELLOW = CYAN = MAGENTA = BLUE = WHITE = ""
    Fore = _C()
    Style = _Dummy()

warnings.filterwarnings("ignore", category=UserWarning)

# ---------------------------
# ÂèØË™øÂèÉÊï∏
# ---------------------------
CHUNK_SIZE_CSV = 100_000       # CSV ÂàÜÂ°äÂ§ßÂ∞è
MAX_REASONABLE_COLUMNS = 2000   # ÊãíÊî∂ÈÅéÂØ¨Ë°®Ê†ºÔºàÁñë‰ººËß£ÊûêÈåØË™§Ôºâ
OUT_DIR = Path("./output")
OUT_DIR.mkdir(parents=True, exist_ok=True)

MASTER_CSV = OUT_DIR / "integrated_master.csv"
HK_IN_AU_CSV = OUT_DIR / "hk_in_au.csv"
UNCERTAIN_CSV = OUT_DIR / "uncertain.csv"
NOT_HK_CSV = OUT_DIR / "not_hk.csv"

SURNAME_STATS_CSV = OUT_DIR / "surname_stats.csv"
DOMAIN_STATS_CSV = OUT_DIR / "email_domain_stats.csv"
LABEL_COUNTS_CSV = OUT_DIR / "label_counts.csv"
COUNTRY_LABEL_PIVOT_CSV = OUT_DIR / "country_label_pivot.csv"

# ÂøÖË¶ÅÊ¨Ñ‰ΩçÊ®ôÊ∫ñÂêç
NEEDED_COLS = ["name", "email", "phone", "address"]

# Ê¨Ñ‰ΩçÊò†Â∞ÑÔºàÂ∏∏Ë¶ãËÆäÈ´î -> Ê®ôÊ∫ñÂêçÔºâ
COL_MAPS = {
    # name
    "name": "name", "ÂßìÂêç": "name", "full name": "name", "first name": "name", "last name": "name",
    "contact name": "name", "person": "name", "user": "name", "ÂÆ¢Êà∑": "name", "ÂêçÁ®±": "name",
    # email
    "email": "email", "e-mail": "email", "mail": "email", "ÈÉµÁÆ±": "email", "ÈÇÆÁÆ±": "email",
    "ÈõªÂ≠êÈÉµ‰ª∂": "email", "ÈõªÂ≠êÈÉµÁÆ±": "email",
    # phone
    "phone": "phone", "tel": "phone", "telephone": "phone", "mobile": "phone", "cell": "phone",
    "cellphone": "phone", "ÊâãÊ©ü": "phone", "ÊâãÊú∫Âè∑": "phone", "ÈõªË©±": "phone",
    # address
    "address": "address", "addr": "address", "‰ΩèÂùÄ": "address", "Âú∞ÂùÄ": "address", "Ë°óÈÅì": "address",
    "location": "address"
}

# ---------------------------
# Âü∫Á§éÁâπÂæµÂ∫´ÔºàÂèØË¢´ÂãïÊÖã list ÁñäÂä†Ôºâ
# ---------------------------
base_hk_surnames = [
    "chan","cheung","wong","lee","ho","ng","yuen","chiu","lam","kwok","leung","mak",
    "chu","tsang","chow","au","fung","kwan","ip","lo","man","tam","to","wan","yu","yip",
    "lau","poon","pang","hui","cheng","shum","shek","ngai","lok","ko","law"
]
base_cantonese_spellings = [
    "cheung","chow","tsang","chu","yuen","kwok","wai","ho","man","poon","ng"
]
base_hk_domains = [
    "hku.hk","cuhk.edu.hk","hkbu.edu.hk","polyu.edu.hk",
    "cityu.edu.hk","ln.edu.hk","eduhk.hk","ust.hk",
    "netvigator.com","yahoo.com.hk","hotmail.com.hk"
]
base_hk_suburbs = [
    "chatswood","hurstville","eastwood","burwood",
    "box hill","glen waverley","doncaster","rhodes"
]
base_hk_phones = ["+852","852"]

# ---------------------------
# Â∑•ÂÖ∑ÔºöÈ°èËâ≤ log
# ---------------------------
def info(msg): print(Fore.CYAN + msg + Style.RESET_ALL)
def good(msg): print(Fore.GREEN + "‚úÖ " + msg + Style.RESET_ALL)
def warn(msg): print(Fore.YELLOW + "‚ö†Ô∏è " + msg + Style.RESET_ALL)
def bad(msg):  print(Fore.RED + "‚ùå " + msg + Style.RESET_ALL)

# ---------------------------
# Ê™îÂêçÊé®Ê∏¨ÂúãÂà•ÔºàÂèØËá™Ë°åÊì¥ÂÖÖÔºâ
# ---------------------------
COUNTRY_MAP = {
    # Ëã±ÊñáÁ∏ÆÂØ´
    "AU": "AU", "AUS": "AU", "Australia": "AU",
    "UK": "UK", "GB": "UK", "GBR": "UK",
    "CA": "CA", "CAN": "CA", "Canada": "CA",
    "DE": "DE", "GER": "DE", "Germany": "DE",
    "IT": "IT", "ITA": "IT", "Italy": "IT",
    "FR": "FR", "FRA": "FR", "France": "FR",
    "US": "US", "USA": "US",
    "PL": "PL", "POL": "PL",
    # Â∏∏Ë¶ã‰∏≠ÊñáÔºàÊ®°Á≥äÂåπÈÖçÔºâ
    "Êæ≥": "AU", "Ëã±": "UK", "Âæ∑": "DE", "Áæ©Â§ßÂà©": "IT", "ÊÑèÂ§ßÂà©": "IT", "Ê≥ï": "FR", "Âä†": "CA", "Áæé": "US",
}

def guess_country_code_from_filename(path: str) -> str:
    name = Path(path).name
    stem = Path(path).stem
    tokens = re.split(r"[^\w\u4e00-\u9fff]+", stem)
    candidates = []
    for t in tokens:
        if not t: 
            continue
        t_up = t.upper()
        t_cn = t
        for k, v in COUNTRY_MAP.items():
            if len(k) <= 3:  # Ëã±ÊñáÁü≠Á¢º
                if t_up == k or k in t_up:
                    candidates.append(v)
            else:  # ‰∏≠ÊñáË©û
                if k in t_cn:
                    candidates.append(v)
    if not candidates:
        # Á∂≤ÂüüÁ∑öÁ¥¢
        if ".com.au" in name.lower() or name.lower().endswith("_au"):
            return "AU"
    return candidates[0] if candidates else ""

# ---------------------------
# ÂãïÊÖãÁâπÂæµÂ∫´
# ---------------------------
def load_dynamic_list(file, base_list):
    if os.path.exists(file):
        with open(file, "r", encoding="utf-8", errors="ignore") as f:
            dynamic = [x.strip().lower() for x in f if x.strip()]
        return list(dict.fromkeys(base_list + dynamic))  # ÂéªÈáç‰øùÂ∫è
    return base_list

def save_new_candidates(counter: Counter, file: str, threshold: int, existing: set):
    new_items = [it for it, c in counter.items() if c >= threshold and it and it not in existing]
    if new_items:
        with open(file, "a", encoding="utf-8") as f:
            for it in new_items:
                f.write(it + "\n")
        good(f"‚ú® Êñ∞Â¢û {len(new_items)} È†ÖÂà∞ {file}")

# ---------------------------
# Ê¨Ñ‰ΩçÊ≠£Ë¶èÂåñ
# ---------------------------
def to_str_series(s: pd.Series) -> pd.Series:
    # ÂÆâÂÖ®Â≠ó‰∏≤ÂåñÔºöNaN ‚Üí "", ÂÖ∂‰ªñ ‚Üí str
    return s.map(lambda x: "" if pd.isna(x) else (str(x).strip()))

def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:
    # Ê¨ÑÂêç‰∏ÄÂæãËΩâÂ≠ó‰∏≤ÔºåÈÅøÂÖç 'int' Ê≤íÊúâ strip()
    df.columns = [str(c) for c in df.columns]

    if df.shape[1] > MAX_REASONABLE_COLUMNS:
        df.attrs["_too_wide"] = True
        return df

    rename = {}
    for c in df.columns:
        c_norm = str(c).strip().lower()
        rename[c] = COL_MAPS.get(c_norm, c_norm)
    df = df.rename(columns=rename)

    # Áº∫ÁöÑË£úÈΩä
    for col in NEEDED_COLS:
        if col not in df.columns:
            df[col] = ""

    # Âè™‰øùÁïôÂøÖË¶ÅÊ¨Ñ‰Ωç + ÂÖ∂È§òÔºàÁ∂≠ÊåÅÂéüÈ†ÜÂ∫èÔºâ
    ordered = NEEDED_COLS + [c for c in df.columns if c not in NEEDED_COLS]
    df = df[ordered]

    # ÂøÖË¶ÅÊ¨Ñ‰ΩçÂº∑Âà∂Â≠ó‰∏≤Âåñ
    for col in NEEDED_COLS:
        df[col] = to_str_series(df[col])

    return df

# ---------------------------
# ÂêÑÊ†ºÂºèËÆÄÂèñÔºà‰∏≤ÊµÅ/yield DataFrameÔºâ
# ---------------------------
def iter_from_csv(file: str):
    total_rows = None
    # ÂòóË©¶‰º∞Ë°åÊï∏Ôºà‰∏ç‰øùË≠âÊ∫ñÁ¢∫ÔºåÂè™ÁÇ∫ÈÄ≤Â∫¶Ê¢ùÔºâ
    try:
        with open(file, "rb") as f:
            total_rows = sum(1 for _ in f)
    except Exception:
        pass

    encodings_try = ["utf-8", "utf-8-sig", "latin-1"]
    for enc in encodings_try:
        try:
            it = pd.read_csv(
                file,
                dtype=str,
                on_bad_lines="skip",
                low_memory=False,
                chunksize=CHUNK_SIZE_CSV,
                encoding=enc
            )
            iterator = it
            break
        except Exception as e:
            warn(f"{file} ‰ª• {enc} ËÆÄÂèñÂ§±ÊïóÔºö{e}")
            iterator = None
    if iterator is None:
        bad(f"{file} CSV ËÆÄÂèñÂ§±ÊïóÔºåË∑≥ÈÅé")
        return

    iterable = iterator
    if tqdm:
        iterable = tqdm(iterator, desc=f"üì• {Path(file).name}", unit="chunk")

    for chunk in iterable:
        if chunk is None or chunk.empty:
            continue
        chunk = chunk.fillna("")
        chunk = normalize_columns(chunk)
        if chunk.attrs.get("_too_wide"):
            bad(f"{file} Ê¨Ñ‰ΩçÊï∏Áï∞Â∏∏Ôºà>{MAX_REASONABLE_COLUMNS}ÔºâÔºåË∑≥ÈÅé")
            continue
        yield chunk

def iter_from_xlsx(file: str):
    try:
        xls = pd.ExcelFile(file, engine="openpyxl")
    except Exception as e:
        bad(f"{file} ËÆÄ .xlsx Â§±ÊïóÔºö{e}")
        return

    sheets = xls.sheet_names
    iterable = sheets
    if tqdm:
        iterable = tqdm(sheets, desc=f"üìó {Path(file).name}", unit="sheet")

    for sh in iterable:
        try:
            df = pd.read_excel(file, sheet_name=sh, dtype=str, engine="openpyxl")
            if df is None or df.empty:
                continue
            df = df.fillna("")
            df = normalize_columns(df)
            if df.attrs.get("_too_wide"):
                bad(f"{file}::{sh} Ê¨Ñ‰ΩçÊï∏Áï∞Â∏∏Ôºà>{MAX_REASONABLE_COLUMNS}ÔºâÔºåË∑≥ÈÅé")
                continue
            df["sheet_name"] = sh
            yield df
        except Exception as e:
            bad(f"{file}::'{sh}' ËÆÄÂèñÂ§±ÊïóÔºö{e}")

def read_xls_via_pyexcel(file: str):
    try:
        from pyexcel_xls import get_data
    except Exception as e:
        bad(f"{file} ÈúÄË¶ÅÂ•ó‰ª∂ pyexcel-xlsÔºöË´ãÂÖà `pip install pyexcel-xls pyexcel-io`ÔºõÈåØË™§Ôºö{e}")
        return []

    try:
        data = get_data(file)  # dict: sheet_name -> rows (list[list])
    except Exception as e:
        bad(f"{file} ‰ΩøÁî® pyexcel-xls Ëß£ÊûêÂ§±ÊïóÔºö{e}")
        return []

    frames = []
    for sh, rows in data.items():
        if not rows:
            continue
        header = rows[0]
        # Ëã•È¶ñÂàóÈùûÂ≠ó‰∏≤Ê¨ÑÂêçÔºåÁîüÊàêÈÄöÁî®Ê¨ÑÂêç
        if any(isinstance(x, str) and x.strip() for x in header):
            cols = [str(x).strip() if x is not None else f"col{i}" for i, x in enumerate(header)]
            body = rows[1:]
        else:
            cols = [f"col{i}" for i in range(len(header))]
            body = rows
        df = pd.DataFrame(body, columns=cols)
        df = df.fillna("")
        df = normalize_columns(df)
        if df.attrs.get("_too_wide"):
            bad(f"{file}::{sh} Ê¨Ñ‰ΩçÊï∏Áï∞Â∏∏Ôºà>{MAX_REASONABLE_COLUMNS}ÔºâÔºåË∑≥ÈÅé")
            continue
        df["sheet_name"] = sh
        frames.append(df)
    return frames

def iter_from_xls(file: str):
    # ÂÑ™ÂÖàË©¶ xlrd
    try:
        df = pd.read_excel(file, dtype=str, engine="xlrd")
        df = df.fillna("")
        df = normalize_columns(df)
        if not df.empty:
            df["sheet_name"] = ""
            yield df
            return
    except Exception as e1:
        warn(f"{file} xlrd ËÆÄ .xls Â§±ÊïóÔºö{e1}ÔºõÊîπÁî® pyexcel-xls")

    # fallback pyexcel-xls
    frames = read_xls_via_pyexcel(file)
    for df in frames:
        yield df

def iter_frames_from_file(file: str):
    file_l = file.lower()
    if file_l.endswith(".csv"):
        yield from iter_from_csv(file)
    elif file_l.endswith(".xlsx"):
        yield from iter_from_xlsx(file)
    elif file_l.endswith(".xls"):
        yield from iter_from_xls(file)
    elif file_l.endswith(".txt"):
        # ÂòóË©¶ tab/ÈÄóËôü
        for sep in ["\t", ",", ";", "|"]:
            try:
                it = pd.read_csv(file, sep=sep, dtype=str, on_bad_lines="skip", encoding="utf-8", low_memory=False)
                if it is None or it.empty:
                    continue
                it = it.fillna("")
                it = normalize_columns(it)
                if it.attrs.get("_too_wide"):
                    bad(f"{file} Ê¨Ñ‰ΩçÊï∏Áï∞Â∏∏Ôºà>{MAX_REASONABLE_COLUMNS}ÔºâÔºåË∑≥ÈÅé")
                    continue
                yield it
                break
            except Exception:
                continue
    else:
        warn(f"{file} Êú™ÊîØÊè¥Ê†ºÂºèÔºåË∑≥ÈÅé")

# ---------------------------
# Ë©ïÂàÜÔºàÂêëÈáèÂåñ + ÂÆâÂÖ®Â≠ó‰∏≤Ôºâ
# ---------------------------
def build_patterns(hk_surnames, cantonese_spellings, hk_domains, hk_suburbs):
    if hk_surnames:
        pat_surname = r"\b(?:%s)\b" % "|".join(re.escape(x) for x in hk_surnames)
    else:
        pat_surname = ""
    if cantonese_spellings:
        pat_canton = r"(?:%s)" % "|".join(re.escape(x) for x in cantonese_spellings)
    else:
        pat_canton = ""
    if hk_domains:
        pat_domains = r"(?:%s)" % "|".join(re.escape(x) for x in hk_domains)
    else:
        pat_domains = ""
    if hk_suburbs:
        pat_suburbs = r"(?:%s)" % "|".join(re.escape(x) for x in hk_suburbs)
    else:
        pat_suburbs = ""
    return pat_surname, pat_canton, pat_domains, pat_suburbs

def score_block(df: pd.DataFrame,
                hk_surnames, cantonese_spellings, hk_domains, hk_suburbs, hk_phones):
    name_lc   = df["name"].astype(str).str.lower()
    email_lc  = df["email"].astype(str).str.lower()
    phone_txt = df["phone"].astype(str).str.strip()
    addr_lc   = df["address"].astype(str).str.lower()

    pat_surname, pat_canton, pat_domains, pat_suburbs = build_patterns(
        hk_surnames, cantonese_spellings, hk_domains, hk_suburbs
    )

    # ÂêÑÁâπÂæµÂ∏ÉÊûó
    b_hk_surname   = name_lc.str.contains(pat_surname, regex=True, na=False) if pat_surname else pd.Series([False]*len(df))
    b_canton_name  = name_lc.str.contains(pat_canton, regex=True, na=False)  if pat_canton else pd.Series([False]*len(df))
    b_cjk_name     = df["name"].astype(str).str.contains(r"[\u4e00-\u9fff]", regex=True, na=False)

    b_email_domain = (
        email_lc.str.endswith(".hk", na=False) |
        (email_lc.str.contains(pat_domains, regex=True, na=False) if pat_domains else False)
    )
    b_canton_email = email_lc.str.contains(pat_canton, regex=True, na=False) if pat_canton else pd.Series([False]*len(df))

    b_hk_phone_pref = pd.Series([False]*len(df))
    if hk_phones:
        b_hk_phone_pref = phone_txt.apply(lambda x: any(x.startswith(ph) for ph in hk_phones))

    # È¶ôÊ∏ØÊâãÊ©üÊÆµÔºàÂü∫Êñº‰Ω†ÂéüÂÖàË¶èÂâáÔºö4ÈñãÈ†≠+8‰ΩçÔºâ
    b_hk_mobile = phone_txt.str.match(r"^4\d{7}$", na=False)

    b_addr_suburb = addr_lc.str.contains(pat_suburbs, regex=True, na=False) if pat_suburbs else pd.Series([False]*len(df))

    # ÂêÑÁâπÂæµÊ¨äÈáç
    score = (
        b_hk_surname.astype(int)   * 40 +
        b_canton_name.astype(int)  * 20 +
        b_cjk_name.astype(int)     * 20 +
        b_email_domain.astype(int) * 40 +
        b_canton_email.astype(int) * 15 +
        b_hk_phone_pref.astype(int)* 50 +
        b_hk_mobile.astype(int)    * 20 +
        b_addr_suburb.astype(int)  * 30
    )

    # Ê®ôÁ±§
    def classify(s):
        if s >= 80:
            return "HK_in_AU"
        elif s >= 45:
            return "Uncertain"
        else:
            return "Not_HK"
    label = score.map(classify)

    # ÁêÜÁî±ÔºàÈÅøÂÖç ufunc Â≠ó‰∏≤Áõ∏Âä†ÈåØË™§ÔºåÁî®ÈÄêÂàó joinÔºâ
    reasons_cols = {
        "È¶ôÊ∏ØÂ∏∏Ë¶ãÂßìÊ∞è": b_hk_surname,
        "Á≤µË™ûÊãºÈü≥ÔºàÂßìÂêçÔºâ": b_canton_name,
        "‰∏≠ÊñáÂßìÂêç": b_cjk_name,
        "È¶ôÊ∏Ø‰ø°ÁÆ±/ÊïôËÇ≤Âüü": b_email_domain,
        "Email Á≤µË™ûÊãºÈü≥": b_canton_email,
        "È¶ôÊ∏ØÈõªË©±ÂâçÁ∂¥": b_hk_phone_pref,
        "È¶ôÊ∏ØÊâãÊ©üËôüÊÆµ": b_hk_mobile,
        "Êæ≥Ê¥≤Ê∏Ø‰∫∫Â∏∏‰ΩèÂçÄ": b_addr_suburb,
    }
    # ÂÖàÂª∫‰∏ÄÂÄã DataFrame Âè™ÊîæÂ≠ó‰∏≤ÁâáÊÆµÊàñÁ©∫Â≠ó‰∏≤
    _reasons_df = pd.DataFrame({k: pd.Series([""]*len(df), dtype=object) for k in reasons_cols})
    for k, mask in reasons_cols.items():
        _reasons_df.loc[mask, k] = k

    reasons = _reasons_df.apply(lambda row: "; ".join([x for x in row if x]), axis=1)

    return score, label, reasons

# ---------------------------
# ‰∏≤ÊµÅÂØ´Ê™îÔºàÈÅøÂÖç‰∏ÄÊ¨°ÊÄß‰ΩµË°®Ôºâ
# ---------------------------
def append_csv(path: Path, df: pd.DataFrame):
    header = not path.exists()
    df.to_csv(path, index=False, encoding="utf-8-sig", mode="a", header=header)

# ---------------------------
# ‰∏ªÊµÅÁ®ã
# ---------------------------
def process_all(base_dir: str):
    # ÂãïÊÖãÁâπÂæµÂ∫´ËºâÂÖ•
    hk_surnames = load_dynamic_list("dynamic_surnames.txt", base_hk_surnames)
    cantonese_spellings = load_dynamic_list("dynamic_spellings.txt", base_cantonese_spellings)
    hk_domains = load_dynamic_list("dynamic_domains.txt", base_hk_domains)
    hk_suburbs = load_dynamic_list("dynamic_suburbs.txt", base_hk_suburbs)
    hk_phones = load_dynamic_list("dynamic_phones.txt", base_hk_phones)

    info("üîß ÁâπÂæµÂ∫´Ôºö")
    print(f"  ÂßìÊ∞è {len(hk_surnames)} / Á≤µË™ûÊãºÈü≥ {len(cantonese_spellings)} / ÂüüÂêç {len(hk_domains)} / Êæ≥Ê¥≤Âú∞ÂçÄ {len(hk_suburbs)} / ÈõªË©±ÂâçÁ∂¥ {len(hk_phones)}")

    # ÁõÆÊ®ôÊ™îÊ°à
    exts = ("*.csv", "*.xlsx", "*.xls", "*.txt")
    files = []
    for ext in exts:
        files.extend(glob.glob(str(Path(base_dir) / "**" / ext), recursive=True))
    if not files:
        warn("Ê≤íÊúâÊâæÂà∞‰ªª‰ΩïË≥áÊñôÊ™î")
        return

    info(f"üìÇ ÁôºÁèæ {len(files)} ÂÄãÊ™îÊ°à")

    # Áµ±Ë®àÂô®Ôºà‰∏≤ÊµÅÁ¥ØË®àÔºâ
    label_counts = Counter()
    country_label = Counter()
    surname_counter = Counter()
    domain_counter = Counter()

    total_rows_in = 0

    # ÁßªÈô§ËàäËº∏Âá∫
    for p in [MASTER_CSV, HK_IN_AU_CSV, UNCERTAIN_CSV, NOT_HK_CSV,
              SURNAME_STATS_CSV, DOMAIN_STATS_CSV, LABEL_COUNTS_CSV, COUNTRY_LABEL_PIVOT_CSV]:
        try:
            if p.exists():
                p.unlink()
        except Exception:
            pass

    # ‰∏ªËø≠‰ª£
    iterable = files
    if tqdm:
        iterable = tqdm(files, desc="üßæ Files", unit="file")

    for file in iterable:
        country_code = guess_country_code_from_filename(file)

        try:
            frame_iter = iter_frames_from_file(file)
            any_yield = False
            for df in frame_iter:
                any_yield = True
                rows_before = len(df)

                # Â¢ûË£úËøΩÊ∫ØÊ¨Ñ‰Ωç
                if "sheet_name" not in df.columns:
                    df["sheet_name"] = ""
                df["source_file"] = str(Path(file).as_posix())
                df["country_code"] = country_code

                # Ë©ïÂàÜ + Ê®ôÁ±§ + ÁêÜÁî±
                score, label, reasons = score_block(
                    df, hk_surnames, cantonese_spellings, hk_domains, hk_suburbs, hk_phones
                )
                df["score"] = score
                df["label"] = label
                df["reasons"] = reasons

                # Á¥ØË®àÁµ±Ë®àÔºàÈÅøÂÖçÂ§ßË®òÊÜ∂È´îÔºâ
                total_rows_in += rows_before
                label_counts.update(label.tolist())
                if country_code:
                    for lb in label.tolist():
                        country_label[(country_code, lb)] += 1

                # ÂßìÊ∞èËàáÁ∂≤ÂüüÁµ±Ë®àÔºàÂ≠ó‰∏≤ÂÆâÂÖ®Ôºâ
                first_surnames = df["name"].map(
                    lambda x: (x.strip().split()[0].lower() if isinstance(x, str) and x.strip() else "")
                )
                domains = df["email"].map(
                    lambda x: (x.split("@")[-1].strip().lower() if isinstance(x, str) and "@" in x else "")
                )
                surname_counter.update([s for s in first_surnames if s])
                domain_counter.update([d for d in domains if d])

                # ‰∏≤ÊµÅËº∏Âá∫ÔºöÁ∏ΩË°® & ‰∏âÂàÜÈ°û
                append_csv(MASTER_CSV, df[[
                    "name","email","phone","address",
                    "score","label","reasons","country_code","source_file","sheet_name"
                ]])

                append_csv(HK_IN_AU_CSV, df[df["label"]=="HK_in_AU"][[
                    "name","email","phone","address",
                    "score","reasons","country_code","source_file","sheet_name"
                ]])

                append_csv(UNCERTAIN_CSV, df[df["label"]=="Uncertain"][[
                    "name","email","phone","address",
                    "score","reasons","country_code","source_file","sheet_name"
                ]])

                append_csv(NOT_HK_CSV, df[df["label"]=="Not_HK"][[
                    "name","email","phone","address",
                    "score","reasons","country_code","source_file","sheet_name"
                ]])

            if not any_yield:
                warn(f"{file} Ê≤íÊúâÂèØÁî®Ë≥áÊñôÔºàÊàñÊ†ºÂºè‰∏çÊîØÊè¥Ôºâ")
        except Exception as e:
            bad(f"{file} ËÆÄÂèñ/ËôïÁêÜÂ§±ÊïóÔºö{e}")

    # ---------------------------
    # ÂΩôÁ∏ΩËº∏Âá∫
    # ---------------------------
    info("\nüßÆ Ëº∏Âá∫ÂΩôÁ∏Ω...")

    # Ê®ôÁ±§Áµ±Ë®à
    pd.DataFrame(
        [{"label": k, "count": v} for k, v in sorted(label_counts.items(), key=lambda x: (-x[1], x[0]))]
    ).to_csv(LABEL_COUNTS_CSV, index=False, encoding="utf-8-sig")

    # ÂúãÂÆ∂ √ó Ê®ôÁ±§
    # ËΩâÊàêÈÄèË¶ñË°®
    country_label_map = defaultdict(dict)
    for (cty, lb), cnt in country_label.items():
        country_label_map[cty][lb] = cnt
    rows = []
    all_labels = sorted({lb for (_, lb) in country_label.keys()})
    for cty, d in sorted(country_label_map.items()):
        row = {"country_code": cty}
        for lb in all_labels:
            row[lb] = d.get(lb, 0)
        row["total"] = sum(d.values())
        rows.append(row)
    if rows:
        pd.DataFrame(rows).to_csv(COUNTRY_LABEL_PIVOT_CSV, index=False, encoding="utf-8-sig")

    # ÂßìÊ∞è / Á∂≤Âüü Áµ±Ë®à
    pd.Series(surname_counter).sort_values(ascending=False).to_csv(SURNAME_STATS_CSV, header=["count"], encoding="utf-8-sig")
    pd.Series(domain_counter).sort_values(ascending=False).to_csv(DOMAIN_STATS_CSV, header=["count"], encoding="utf-8-sig")

    good("\n===== üìä ÂàÜÊûêÂ†±Âëä =====")
    print(f"üìå Á∏ΩÁ≠ÜÊï∏Ôºà‰º∞ÔºâÔºö{total_rows_in}")
    print(f"üü¢ È´òÂèØ‰ø°È¶ôÊ∏ØËÉåÊôØÔºö{label_counts.get('HK_in_AU', 0)}")
    print(f"üü° ‰∏çÁ¢∫ÂÆöÔºö{label_counts.get('Uncertain', 0)}")
    print(f"üî¥ ÈùûÈ¶ôÊ∏ØËÉåÊôØÔºö{label_counts.get('Not_HK', 0)}")
    print("\nüìë ÂΩôÁ∏ΩËº∏Âá∫Ôºö")
    print(f" - {MASTER_CSV.name}")
    print(f" - {LABEL_COUNTS_CSV.name} / {COUNTRY_LABEL_PIVOT_CSV.name}")
    print(f" - {SURNAME_STATS_CSV.name} / {DOMAIN_STATS_CSV.name}")
    print("üìÇ ÂàÜÈ°ûËº∏Âá∫Ôºöhk_in_au.csv / uncertain.csv / not_hk.csv")
    print("üß© ÁâπÂæµÂ∫´Ôºödynamic_surnames.txt / dynamic_domains.txt / dynamic_suburbs.txt / dynamic_phones.txt")

    # ---------------------------
    # ÂãïÊÖãÁâπÂæµÂ∫´Â¢ûË£ú
    # ---------------------------
    info("\nüß† Êõ¥Êñ∞ÂãïÊÖãÁâπÂæµÂ∫´ÂÄôÈÅ∏...")
    existing_surnames = set(hk_surnames)
    existing_domains = set(hk_domains)
    save_new_candidates(surname_counter, "dynamic_surnames.txt", threshold=50, existing=existing_surnames)
    save_new_candidates(domain_counter, "dynamic_domains.txt", threshold=50, existing=existing_domains)

# ---------------------------
# ÂÖ•Âè£
# ---------------------------
if __name__ == "__main__":
    base = sys.argv[1] if len(sys.argv) > 1 else "."
    base = str(Path(base).resolve())
    info(f"üöÄ ÈñãÂßãËôïÁêÜÔºö{base}")
    process_all(base)
