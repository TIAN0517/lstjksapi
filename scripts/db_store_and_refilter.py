#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“å…¥åº“ + å‘é‡åŒ–äºŒæ¬¡ç­›é€‰
æå‡åäººè¯†åˆ«ç²¾å‡†åº¦
"""

import pandas as pd
import psycopg2
from psycopg2.extras import execute_values
import logging
from typing import List, Dict
import numpy as np

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    'host': 'localhost',
    'port': 5432,
    'database': 'bossjy_huaqiao',
    'user': 'bossjy',
    'password': 'your_password'  # éœ€è¦é…ç½®
}

def create_tables(conn):
    """åˆ›å»ºæ•°æ®åº“è¡¨"""
    cursor = conn.cursor()

    # 1. åˆ›å»ºè¯†åˆ«ç»“æœè¡¨
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS chinese_identification_results (
        id BIGSERIAL PRIMARY KEY,

        -- åŸå§‹æ•°æ®
        original_name VARCHAR(200) NOT NULL,
        phone VARCHAR(50),
        email VARCHAR(200),
        gender VARCHAR(20),
        city VARCHAR(100),

        -- å§“ååˆ†ç¦»
        surname VARCHAR(50),
        given_name VARCHAR(150),
        surname_chinese VARCHAR(10),

        -- è¯†åˆ«ç»“æœ
        label VARCHAR(50) NOT NULL,  -- CN_Chinese/HK_HongKong/Unknown
        confidence VARCHAR(20) NOT NULL,  -- HIGH/MEDIUM/LOW
        total_score FLOAT NOT NULL,
        phone_score FLOAT DEFAULT 0,
        surname_score FLOAT DEFAULT 0,
        email_score FLOAT DEFAULT 0,

        -- è¯†åˆ«ä¾æ®
        reasons TEXT[],

        -- å…ƒæ•°æ®
        source_file VARCHAR(200),
        created_at TIMESTAMP DEFAULT NOW(),

        -- ç´¢å¼•
        CONSTRAINT unique_record UNIQUE(original_name, phone, email)
    );

    CREATE INDEX IF NOT EXISTS idx_label ON chinese_identification_results(label);
    CREATE INDEX IF NOT EXISTS idx_confidence ON chinese_identification_results(confidence);
    CREATE INDEX IF NOT EXISTS idx_total_score ON chinese_identification_results(total_score);
    CREATE INDEX IF NOT EXISTS idx_surname ON chinese_identification_results(surname);
    """)

    # 2. åˆ›å»ºå‘é‡å¢å¼ºè¡¨ï¼ˆç”¨äºäºŒæ¬¡ç­›é€‰ï¼‰
    cursor.execute("""
    CREATE TABLE IF NOT EXISTS vector_enhanced_results (
        id BIGSERIAL PRIMARY KEY,
        original_id BIGINT REFERENCES chinese_identification_results(id),

        -- å‘é‡ç›¸ä¼¼åº¦åˆ†æ•°
        surname_vector_score FLOAT,
        name_pattern_score FLOAT,
        hongkong_similarity_score FLOAT,

        -- å¢å¼ºåçš„æ ‡ç­¾
        enhanced_label VARCHAR(50),
        enhanced_confidence VARCHAR(20),
        enhanced_total_score FLOAT,

        -- å¢å¼ºä¾æ®
        enhancement_reasons TEXT[],

        created_at TIMESTAMP DEFAULT NOW()
    );
    """)

    conn.commit()
    logger.info("âœ… æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆ")

def bulk_insert_results(conn, df: pd.DataFrame, source_file: str):
    """æ‰¹é‡æ’å…¥è¯†åˆ«ç»“æœ"""
    cursor = conn.cursor()

    # å‡†å¤‡æ•°æ®
    records = []
    for _, row in df.iterrows():
        records.append((
            row.get('Full Name', ''),
            row.get('Phone Number', ''),
            row.get('Email', ''),
            row.get('Gender', ''),
            row.get('City', ''),
            row.get('Surname', ''),
            row.get('Given Name', ''),
            row.get('Surname Chinese', ''),
            row.get('Label', 'Unknown'),
            row.get('Confidence', 'UNKNOWN'),
            float(row.get('Total Score', 0)),
            float(row.get('Phone Score', 0)),
            float(row.get('Surname Score', 0)),
            float(row.get('Email Score', 0)),
            row.get('Reasons', '').split(' | ') if row.get('Reasons') else [],
            source_file
        ))

    # æ‰¹é‡æ’å…¥
    execute_values(
        cursor,
        """
        INSERT INTO chinese_identification_results
        (original_name, phone, email, gender, city, surname, given_name,
         surname_chinese, label, confidence, total_score, phone_score,
         surname_score, email_score, reasons, source_file)
        VALUES %s
        ON CONFLICT (original_name, phone, email) DO NOTHING
        """,
        records
    )

    conn.commit()
    inserted = cursor.rowcount
    logger.info(f"âœ… æ’å…¥ {inserted} æ¡è®°å½•åˆ°æ•°æ®åº“")
    return inserted

def vector_enhanced_filter(conn):
    """
    åŸºäºå‘é‡å’Œæ¨¡å¼çš„äºŒæ¬¡ç­›é€‰
    æå‡è¯†åˆ«ç²¾å‡†åº¦
    """
    cursor = conn.cursor()

    # 1. åŸºäºå§“æ°ç›¸ä¼¼åº¦çš„äºŒæ¬¡ç­›é€‰
    logger.info("ğŸ” æ‰§è¡Œå§“æ°å‘é‡ç›¸ä¼¼åº¦ç­›é€‰...")

    cursor.execute("""
    WITH surname_candidates AS (
        -- æ‰¾å‡ºæ‰€æœ‰å¯èƒ½çš„åäººå§“æ°ï¼ˆåŒ…æ‹¬ä½ç½®ä¿¡åº¦ï¼‰
        SELECT id, original_name, surname, phone, email,
               total_score, confidence
        FROM chinese_identification_results
        WHERE surname IS NOT NULL
          AND surname != ''
          AND confidence IN ('LOW', 'UNKNOWN')  -- é‡ç‚¹å…³æ³¨è¢«ä½ä¼°çš„
    ),
    hongkong_patterns AS (
        -- ä»é¦™æ¸¯æ ·æœ¬ä¸­æå–é«˜é¢‘æ¨¡å¼
        SELECT DISTINCT surname
        FROM chinese_identification_results
        WHERE label = 'HK_HongKong'
          AND confidence IN ('HIGH', 'MEDIUM')
    )
    SELECT
        c.id,
        c.original_name,
        c.surname,
        -- è®¡ç®—ä¸é¦™æ¸¯é«˜é¢‘å§“æ°çš„åŒ¹é…åº¦
        CASE
            WHEN c.surname = ANY(SELECT surname FROM hongkong_patterns) THEN 0.30
            WHEN similarity(c.surname, ANY(SELECT surname FROM hongkong_patterns)) > 0.7 THEN 0.20
            ELSE 0
        END as hongkong_similarity,
        -- ç”µè¯å·ç äºŒæ¬¡éªŒè¯
        CASE
            WHEN c.phone ~ '^(61|852)' THEN 0.40
            WHEN c.phone ~ '^86' THEN 0.25
            ELSE 0
        END as phone_boost,
        -- é‚®ç®±äºŒæ¬¡éªŒè¯
        CASE
            WHEN c.email ~ '\.(hk|cn)$' THEN 0.20
            WHEN c.email ~ '@(qq|163|126)\.com' THEN 0.15
            ELSE 0
        END as email_boost
    FROM surname_candidates c
    """)

    enhanced_candidates = cursor.fetchall()

    # 2. é‡æ–°è¯„åˆ†å’Œåˆ†ç±»
    enhanced_records = []
    for record in enhanced_candidates:
        record_id, name, surname, hk_sim, phone_boost, email_boost = record[:6]

        # è®¡ç®—å¢å¼ºåçš„æ€»åˆ†
        enhanced_score = hk_sim + phone_boost + email_boost

        # å¦‚æœå¢å¼ºååˆ†æ•° >= 0.60ï¼Œåˆ™æå‡ä¸ºåäºº/é¦™æ¸¯äºº
        if enhanced_score >= 0.60:
            if phone_boost >= 0.40 or hk_sim >= 0.25:
                enhanced_label = 'HK_HongKong'
            else:
                enhanced_label = 'CN_Chinese'

            if enhanced_score >= 0.75:
                enhanced_conf = 'HIGH'
            elif enhanced_score >= 0.60:
                enhanced_conf = 'MEDIUM'
            else:
                enhanced_conf = 'LOW'

            reasons = []
            if hk_sim > 0:
                reasons.append(f'é¦™æ¸¯å§“æ°æ¨¡å¼åŒ¹é…+{hk_sim:.2f}')
            if phone_boost > 0:
                reasons.append(f'ç”µè¯å·ç å¢å¼º+{phone_boost:.2f}')
            if email_boost > 0:
                reasons.append(f'é‚®ç®±åŸŸåå¢å¼º+{email_boost:.2f}')

            enhanced_records.append((
                record_id, hk_sim, 0, enhanced_score,
                enhanced_label, enhanced_conf, reasons
            ))

    # 3. æ’å…¥å¢å¼ºç»“æœ
    if enhanced_records:
        execute_values(
            cursor,
            """
            INSERT INTO vector_enhanced_results
            (original_id, surname_vector_score, hongkong_similarity_score,
             enhanced_total_score, enhanced_label, enhanced_confidence, enhancement_reasons)
            VALUES %s
            """,
            enhanced_records
        )
        conn.commit()
        logger.info(f"âœ… äºŒæ¬¡ç­›é€‰å‘ç° {len(enhanced_records)} æ¡æ½œåœ¨åäººè®°å½•")

    return len(enhanced_records)

def generate_enhanced_report(conn):
    """ç”Ÿæˆå¢å¼ºåçš„è¯†åˆ«æŠ¥å‘Š"""
    cursor = conn.cursor()

    # 1. åŸå§‹è¯†åˆ«ç»Ÿè®¡
    cursor.execute("""
    SELECT
        label,
        confidence,
        COUNT(*) as count,
        AVG(total_score) as avg_score
    FROM chinese_identification_results
    GROUP BY label, confidence
    ORDER BY label, confidence
    """)

    print("\n" + "="*60)
    print("ğŸ“Š åŸå§‹è¯†åˆ«ç»“æœç»Ÿè®¡")
    print("="*60)
    for row in cursor.fetchall():
        print(f"  {row[0]:15} {row[1]:10} - {row[2]:5}æ¡ (å¹³å‡åˆ†:{row[3]:.3f})")

    # 2. å¢å¼ºåç»Ÿè®¡
    cursor.execute("""
    SELECT
        enhanced_label,
        enhanced_confidence,
        COUNT(*) as count,
        AVG(enhanced_total_score) as avg_score
    FROM vector_enhanced_results
    GROUP BY enhanced_label, enhanced_confidence
    ORDER BY enhanced_label, enhanced_confidence
    """)

    print("\n" + "="*60)
    print("ğŸš€ å‘é‡å¢å¼ºåæ–°å‘ç°")
    print("="*60)
    enhanced_data = cursor.fetchall()
    if enhanced_data:
        for row in enhanced_data:
            print(f"  {row[0]:15} {row[1]:10} - {row[2]:5}æ¡ (å¹³å‡åˆ†:{row[3]:.3f})")
    else:
        print("  æœªå‘ç°æ–°çš„åäººè®°å½•")

    # 3. æ€»è®¡
    cursor.execute("SELECT COUNT(*) FROM chinese_identification_results")
    total_original = cursor.fetchone()[0]

    cursor.execute("SELECT COUNT(*) FROM vector_enhanced_results")
    total_enhanced = cursor.fetchone()[0]

    print("\n" + "="*60)
    print(f"ğŸ“ˆ æ€»è®¡")
    print("="*60)
    print(f"  åŸå§‹è¯†åˆ«: {total_original} æ¡")
    print(f"  æ–°å¢å‘ç°: {total_enhanced} æ¡")
    print(f"  æå‡ç‡: {(total_enhanced/total_original*100) if total_original > 0 else 0:.1f}%")
    print("="*60 + "\n")

def main():
    """ä¸»æµç¨‹"""
    try:
        # è¿æ¥æ•°æ®åº“
        logger.info("ğŸ“¡ è¿æ¥æ•°æ®åº“...")
        conn = psycopg2.connect(**DB_CONFIG)

        # åˆ›å»ºè¡¨
        create_tables(conn)

        # è¯»å–å¹¶å…¥åº“æ‰€æœ‰è¯†åˆ«ç»“æœ
        import glob
        result_files = glob.glob('data/processed/æ¾³æ´²åäººè¯†åˆ«/*_åäººè¯†åˆ«.xlsx')

        total_inserted = 0
        for file in result_files:
            logger.info(f"ğŸ“ å¤„ç†æ–‡ä»¶: {file}")
            try:
                df = pd.read_excel(file)
                if len(df) > 0:
                    inserted = bulk_insert_results(conn, df, file)
                    total_inserted += inserted
            except Exception as e:
                logger.warning(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {file}: {e}")

        logger.info(f"âœ… æ€»è®¡å…¥åº“ {total_inserted} æ¡è®°å½•")

        # æ‰§è¡Œå‘é‡å¢å¼ºç­›é€‰
        enhanced_count = vector_enhanced_filter(conn)

        # ç”ŸæˆæŠ¥å‘Š
        generate_enhanced_report(conn)

        # å…³é—­è¿æ¥
        conn.close()

        logger.info("âœ… æ‰€æœ‰æ“ä½œå®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ é”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    main()
